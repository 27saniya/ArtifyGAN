{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGX7T1U8mtxN"
   },
   "source": [
    "# Clone the Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eei_H-Bom0bj",
    "outputId": "b2ce648e-d3ee-47a0-f9b1-df5fab9c592a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'AnimeGAN-Pytorch'...\n",
      "remote: Enumerating objects: 52, done.\u001b[K\n",
      "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
      "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
      "remote: Total 52 (delta 2), reused 52 (delta 2), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (52/52), 40.67 MiB | 8.73 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ShilpaShivarudraiah/AnimeGAN-Pytorch.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahi-hzKOCTc4"
   },
   "source": [
    "# Dataset Pre Processing for Cartoon10k (Old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RH2hBIngCR5z",
    "outputId": "bf46dbf6-9427-4d8a-a7e4-198e7dd0cbd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsV49KKF_JgY"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/cartoonset10k.tgz ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ancs1ldFCtJm"
   },
   "outputs": [],
   "source": [
    "#@title Remove all the csv files in the dataset\n",
    "import os\n",
    "path ='/content/cartoonset10k'\n",
    "for file in os.listdir(path):\n",
    "  if '.csv' in file:\n",
    "    os.remove(os.path.join(path,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fdSE-4uDVXX"
   },
   "outputs": [],
   "source": [
    "#@title Check if there any csv file left\n",
    "import os\n",
    "path ='/content/cartoonset10k'\n",
    "for file in os.listdir(path):\n",
    "  if '.csv' in file:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_iUNy14DzzS"
   },
   "source": [
    "## Transform the cartoon dataset to edge-smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cyq3MZ_0DwNx",
    "outputId": "0369bf98-83ce-4745-e2ca-daca8619ca59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/pytorch-animeGAN\n"
     ]
    }
   ],
   "source": [
    "%cd /content/pytorch-animeGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDiZLsfwEAsZ"
   },
   "outputs": [],
   "source": [
    "#Resize the images in cartoonset10k to 256x256\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set the directory path\n",
    "directory = '/content/cartoonset10k'\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'): # Change file extensions to match your files\n",
    "        # Read the image\n",
    "        img = cv2.imread(os.path.join(directory, filename))\n",
    "\n",
    "        # Resize the image to 256x256\n",
    "        img_resized = cv2.resize(img, (256, 256))\n",
    "\n",
    "        # Write the resized image back to disk\n",
    "        cv2.imwrite(os.path.join(directory, filename), img_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zts7CwaeFHun"
   },
   "outputs": [],
   "source": [
    "#Move the foldet inside the dataset folder inside pytorch-animeGAN\n",
    "if not os.path.exists('/content/pytorch-animeGAN/dataset'):\n",
    "  %mkdir /content/pytorch-animeGAN/dataset\n",
    "%mv /content/cartoonset10k /content/pytorch-animeGAN/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1I1jehfDy8t"
   },
   "outputs": [],
   "source": [
    "# Function to make the edges smooth\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import cv2, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_edge_smooth(dataset_name, img_size) :\n",
    "    file_list = glob('dataset/{}/*.*'.format(dataset_name))\n",
    "    save_dir = 'dataset/{}_smooth'.format(dataset_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    kernel_size = 5\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    gauss = cv2.getGaussianKernel(kernel_size, 0)\n",
    "    gauss = gauss * gauss.transpose(1, 0)\n",
    "\n",
    "    for f in tqdm(file_list) :\n",
    "        file_name = os.path.basename(f)\n",
    "\n",
    "        bgr_img = cv2.imread(f)\n",
    "        gray_img = cv2.imread(f, 0)\n",
    "\n",
    "        bgr_img = cv2.resize(bgr_img, (img_size, img_size))\n",
    "        pad_img = np.pad(bgr_img, ((2, 2), (2, 2), (0, 0)), mode='reflect')\n",
    "        gray_img = cv2.resize(gray_img, (img_size, img_size))\n",
    "\n",
    "        edges = cv2.Canny(gray_img, 100, 200)\n",
    "        dilation = cv2.dilate(edges, kernel)\n",
    "\n",
    "        gauss_img = np.copy(bgr_img)\n",
    "        idx = np.where(dilation != 0)\n",
    "        for i in range(np.sum(dilation != 0)):\n",
    "            gauss_img[idx[0][i], idx[1][i], 0] = np.sum(\n",
    "                np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 0], gauss))\n",
    "            gauss_img[idx[0][i], idx[1][i], 1] = np.sum(\n",
    "                np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 1], gauss))\n",
    "            gauss_img[idx[0][i], idx[1][i], 2] = np.sum(\n",
    "                np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 2], gauss))\n",
    "\n",
    "        assert cv2.imwrite(os.path.join(save_dir, file_name), gauss_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uynCJrTGR7h",
    "outputId": "c97a5f28-9a48-4d5a-ab4d-33b3d1bdc6d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [41:13<00:00,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "#Smoothen the edges\n",
    "make_edge_smooth('cartoonset10k',256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5sVCH7BPpId"
   },
   "outputs": [],
   "source": [
    "#Zip the smoothen folder\n",
    "!zip -qr '/content/drive/MyDrive/Preprocessed_Cartoonset_10k.zip' '/content/pytorch-animeGAN/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqYP_MnUW4Cu"
   },
   "source": [
    "# Getting the Train Photo (CelebA Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMLwtGdUW-PJ"
   },
   "outputs": [],
   "source": [
    "!unzip -q '/content/drive/MyDrive/celebA_Kaggle.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEhm2F4kHm4m"
   },
   "outputs": [],
   "source": [
    "#@title Split the dataset\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Path to the folder containing the images\n",
    "folder_path = \"/content/img_align_celeba\"\n",
    "\n",
    "# Create the test and train folders\n",
    "os.mkdir(os.path.join('/content/', \"test\"))\n",
    "os.mkdir(os.path.join('/content/', \"train\"))\n",
    "\n",
    "# Get the list of image files\n",
    "files = os.listdir(folder_path)\n",
    "image_files = [f for f in files if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "\n",
    "# Sort the image files alphabetically\n",
    "image_files.sort()\n",
    "\n",
    "# Copy the first 60k images to the train folder\n",
    "for i in range(60000):\n",
    "    src = os.path.join(folder_path, image_files[i])\n",
    "    dst = os.path.join('/content/', \"train\", image_files[i])\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "# Copy the remaining images to the test folder\n",
    "for i in range(60000, len(image_files)):\n",
    "    src = os.path.join(folder_path, image_files[i])\n",
    "    dst = os.path.join('/content/', \"test\", image_files[i])\n",
    "    shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omWmGYzHVybi"
   },
   "outputs": [],
   "source": [
    "#@title Resizing the dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set the path to the train and test folders\n",
    "train_path = \"/content/train\"\n",
    "test_path = \"/content/test\"\n",
    "\n",
    "# Define the new size for the images\n",
    "new_size = (256, 256)\n",
    "\n",
    "# Loop through the train images and resize them\n",
    "for filename in os.listdir(train_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        filepath = os.path.join(train_path, filename)\n",
    "        with Image.open(filepath) as img:\n",
    "            img = img.resize(new_size)\n",
    "            img.save(filepath)\n",
    "\n",
    "# Loop through the test images and resize them\n",
    "for filename in os.listdir(test_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        filepath = os.path.join(test_path, filename)\n",
    "        with Image.open(filepath) as img:\n",
    "            img = img.resize(new_size)\n",
    "            img.save(filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWm3y_jDowQN"
   },
   "outputs": [],
   "source": [
    "!mkdir ./celebA_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOnAvgFso3Ag"
   },
   "outputs": [],
   "source": [
    "!mv /content/test ./celebA_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywtREzrPo5cZ"
   },
   "outputs": [],
   "source": [
    "!mv /content/train ./celebA_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuTnoymho8cP"
   },
   "outputs": [],
   "source": [
    "!zip -qr './celebA_split.zip' ./celebA_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEsyTR5uvW35"
   },
   "outputs": [],
   "source": [
    "!cp ./celebA_split.zip /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaBFf9Mnme_6"
   },
   "source": [
    "# Extracting the Train and Test Split from CelebA Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcWKkOsbmflW"
   },
   "outputs": [],
   "source": [
    "!unzip -q /content/drive/MyDrive/celebA_split.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3LG-ga-mpR-"
   },
   "outputs": [],
   "source": [
    "!mv /content/celebA_split/test /content/AnimeGAN-Pytorch/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6Kf99zdmqgD"
   },
   "outputs": [],
   "source": [
    "!mv /content/celebA_split/train /content/AnimeGAN-Pytorch/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oP7doh4umsSQ"
   },
   "outputs": [],
   "source": [
    "!mv /content/AnimeGAN-Pytorch/dataset/train /content/AnimeGAN-Pytorch/dataset/train_photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVmFXPkppekP"
   },
   "source": [
    "# Trimming Dataset to reduce training time to 2000 images in cartoonset10k images and 6000 images in train_photo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UaqYuR7pe6_"
   },
   "outputs": [],
   "source": [
    "#Depreceated\n",
    "\n",
    "import os\n",
    "import random\n",
    "path = '/content/AnimeGAN-Pytorch/dataset/cartoonset10k/smooth'\n",
    "files = os.listdir(path)\n",
    "if len(files) <= 2000:\n",
    "    exit()\n",
    "random.shuffle(files)\n",
    "for i in range(len(files) - 2000):\n",
    "    os.remove(os.path.join(path, files[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6t8-Ei35pgYu"
   },
   "outputs": [],
   "source": [
    "#Depereceated\n",
    "print(len(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y73zOJq9phow"
   },
   "outputs": [],
   "source": [
    "#Depereceated\n",
    "import os\n",
    "path = '/content/AnimeGAN-Pytorch/dataset/cartoonset10k/smooth'\n",
    "files_to_keep = os.listdir(path)\n",
    "all_files_path = '/content/AnimeGAN-Pytorch/dataset/cartoonset10k/style'\n",
    "all_files = os.listdir(all_files_path)\n",
    "for file in all_files:\n",
    "    if file not in files_to_keep:\n",
    "        os.remove(os.path.join(all_files_path, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ESkQ0qqpjLV"
   },
   "outputs": [],
   "source": [
    "#Depereceated\n",
    "print(len(os.listdir(all_files_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euRLjg4upkmK"
   },
   "outputs": [],
   "source": [
    "#Depereceated\n",
    "all_files_path = '/content/AnimeGAN-Pytorch/dataset/cartoonset10k/style'\n",
    "all_files = os.listdir(all_files_path)\n",
    "for file in all_files:\n",
    "    if file in files_to_keep:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2K3909kpm-K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "path = '/content/AnimeGAN-Pytorch/dataset/train_photo'\n",
    "files = os.listdir(path)\n",
    "if len(files) <= 6000:\n",
    "    exit()\n",
    "random.shuffle(files)\n",
    "for i in range(len(files) - 6000):\n",
    "    os.remove(os.path.join(path, files[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SYCXqsBpocc"
   },
   "outputs": [],
   "source": [
    "!zip -qr '/content/drive/MyDrive/dataset_trimmed.zip' /content/AnimeGAN-Pytorch/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdDtQquqrO7j"
   },
   "source": [
    "# Unziping the Trimmed Dataset, Deleting the Cartoon10k and combining it with AnimeGAN Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFuqXFuhrP1b",
    "outputId": "a66213ee-ef8f-4f48-a14d-71bb9c2183c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/pytorch-animeGAN\n"
     ]
    }
   ],
   "source": [
    "cd /content/AnimeGAN-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XPRlkp3rSDn"
   },
   "outputs": [],
   "source": [
    "!unzip -q '/content/drive/MyDrive/dataset_trimmed.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPakpAw9rTRL"
   },
   "outputs": [],
   "source": [
    "!unzip -q '/content/drive/MyDrive/AnimeGAN_Dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PE080cfrUad"
   },
   "outputs": [],
   "source": [
    "!rm -rf '/content/AnimeGAN-Pytorch/content/pytorch-animeGAN/dataset/cartoonset10k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLJ56sEtrV1_"
   },
   "outputs": [],
   "source": [
    "!mv '/content/AnimeGAN-Pytorch/dataset/Shinkai' '/content/AnimeGAN-Pytorch/content/pytorch-animeGAN/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZUHWYP_rXGP"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/AnimeGAN-Pytorch/dataset/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J13T91XZrYZD"
   },
   "outputs": [],
   "source": [
    "!mv /content/AnimeGAN-Pytorch/content/pytorch-animeGAN/dataset/* /content/AnimeGAN-Pytorch/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmYHIv0grZvw"
   },
   "outputs": [],
   "source": [
    "!zip -qr '/content/drive/MyDrive/shinkai_celebA.zip' /content/AnimeGAN-Pytorch/dataset/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ahi-hzKOCTc4"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
